{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubuntu/uaa-417-sistemas-de-gestion-de-bases-de-datos-avanzados/blob/main/06_IO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAbQLXH3av2P"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "matplotlib.rcParams['savefig.dpi'] = 144"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sqOLCFtav2R"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install expectexception\n",
        "import expectexception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkdGkEr4av2R"
      },
      "source": [
        "# Importación y exportación de datos\n",
        "\n",
        "<!-- requisito: datos/muestra.txt -->\n",
        "<!-- requisito: datos/csv_sample.txt -->\n",
        "<!-- requisito: datos/bad_csv.csv -->\n",
        "\n",
        "Hasta ahora solo hemos tratado con datos que hemos creado dentro de Python. Generar datos aleatorios es útil para probar ideas, pero queremos trabajar con datos reales. En la mayoría de los casos, esos datos se almacenarán en un archivo, ya sea localmente en la computadora o en línea. En este cuaderno aprenderemos cómo leer y escribir datos en archivos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owWP4vBgav2S"
      },
      "source": [
        "## Python file handles (`open`)\n",
        "\n",
        "En Python interactuamos con archivos en el disco usando los comandos \"abrir\" y \"cerrar\". Hemos incluido un archivo en la carpeta \"datos\" llamado \"sample.txt\". Abrámoslo y leamos su contenido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4b32x0lav2S"
      },
      "outputs": [],
      "source": [
        "f = open('./data/sample.txt', 'r')\n",
        "data = f.read()\n",
        "f.close()\n",
        "\n",
        "print(data)\n",
        "print(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn4xuZF3av2T"
      },
      "source": [
        "Observe que \"abrimos\" el archivo y lo asignamos a \"f\", \"leemos\" los datos de \"f\" y luego cerramos \"f\". ¿Qué es \"f\"? Se llama **identificador de archivo**. Es un objeto que conecta Python con el archivo que \"abrimos\". \"Leemos\" los datos usando esta conexión y luego, una vez que terminamos, \"cerramos\" la conexión. Es un buen hábito \"cerrar\" un identificador de archivo una vez que hayamos terminado con él, por lo que generalmente lo haremos automáticamente usando la palabra clave \"with\" de Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI5GVr0Bav2T"
      },
      "outputs": [],
      "source": [
        "# f is automatically closed\n",
        "# at the end of the body of the with statement\n",
        "with open('./data/sample.txt', 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "print(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PWKXdj9av2U"
      },
      "source": [
        "También podemos leer líneas individuales de un archivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9wFdyC4av2U"
      },
      "outputs": [],
      "source": [
        "with open('./data/sample.txt', 'r') as f:\n",
        "    print(f.readline())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SLBmuflav2U"
      },
      "outputs": [],
      "source": [
        "with open('./data/sample.txt', 'r') as f:\n",
        "    print(f.readlines())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGedQGf2av2V"
      },
      "source": [
        "Escribir datos en archivos es muy similar. La principal diferencia es que cuando \"abrimos\" el archivo, usaremos la bandera \"w\" en lugar de \"r\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X48PwmT2av2V"
      },
      "outputs": [],
      "source": [
        "with open('./data/my_data.txt', 'w') as f:\n",
        "    f.write('This is a new file.')\n",
        "    f.write('I am practicing writing data to disk.')\n",
        "\n",
        "with open('./data/my_data.txt', 'r') as f:\n",
        "    my_data = f.read()\n",
        "\n",
        "print(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev0xqK9Uav2V"
      },
      "source": [
        "No importa con qué frecuencia ejecute la celda anterior, se imprime el mismo resultado. Al abrir el archivo con la bandera `'w'` se sobrescribirá el contenido del archivo. Si queremos agregar algo a lo que ya está en el archivo, tenemos que abrir el archivo con la bandera `'a'` (`'a'` significa _append_)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJM25HYOav2V"
      },
      "outputs": [],
      "source": [
        "with open('./data/my_data.txt', 'a') as f:\n",
        "    f.write('\\nAdding a new line to the file.')\n",
        "\n",
        "with open('./data/my_data.txt', 'r') as f:\n",
        "    my_data = f.read()\n",
        "\n",
        "print(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA5pJeHGav2V"
      },
      "source": [
        "Siempre debemos tener cuidado al escribir en el disco, porque podríamos sobrescribir o alterar datos por accidente. También es fácil encontrar errores al trabajar con archivos, porque es posible que no sepamos de antemano si el archivo al que intentamos acceder existe, o podemos mezclar los indicadores 'r', 'w' y 'a'. ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJStI6uCav2W"
      },
      "outputs": [],
      "source": [
        "%%expect_exception IOError\n",
        "\n",
        "# if a file doesn't exist\n",
        "# we can't open it for reading\n",
        "# (but we can open it for writing)\n",
        "\n",
        "with open('./data/not-exist.txt', 'r') as f:\n",
        "    f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqLHxWUgav2W"
      },
      "outputs": [],
      "source": [
        "%%expect_exception IOError\n",
        "\n",
        "# we can't read a file open for writing\n",
        "\n",
        "with open('./data/fail.txt', 'w') as f:\n",
        "    f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy6BFjaSav2W"
      },
      "outputs": [],
      "source": [
        "%%expect_exception IOError\n",
        "\n",
        "# and we can't write to a file open for reading\n",
        "\n",
        "with open('./data/sample.txt', 'r') as f:\n",
        "    f.write('This will fail')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfxv2clmav2W"
      },
      "source": [
        "¿Podemos prevenir algunos de estos errores? ¿Cómo sabemos qué archivos hay en el disco?\n",
        "\n",
        "## módulo `os`\n",
        "\n",
        "Python tiene un módulo para navegar por el sistema de archivos de la computadora llamado \"os\". Hay muchas herramientas útiles en el módulo `os`, pero hay dos funciones que son más útiles para buscar archivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJKi4DLZav2W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# list the contents of the current directory\n",
        "# ('.' refers to the current directory)\n",
        "os.listdir('.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeywA2-eav2W"
      },
      "source": [
        "El comando `listdir` es la más simple de las dos funciones que cubriremos. Simplemente enumera el contenido de la ruta del directorio que especificamos. Cuando pasamos `'.'` como argumento, `listdir` buscará en el directorio actual. Enumera todos los cuadernos de Jupyter que estamos usando para el curso, así como el subdirectorio \"datos\". Podríamos descubrir qué hay en el subdirectorio `data` buscando en `'./data'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4Y7Niupav2X"
      },
      "outputs": [],
      "source": [
        "os.listdir('./data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGYSf2aLav2X"
      },
      "source": [
        "¿Qué pasaría si quisiéramos encontrar todos los archivos y subdirectorios debajo de un directorio en algún lugar de nuestra computadora? Con `listdir` solo vemos los archivos y subdirectorios bajo el directorio particular que estamos buscando. No podemos usar `listdir` para buscar automáticamente en subdirectorios. Para esto necesitamos usar `walk`, que \"recorre\" todos los subdirectorios debajo de nuestro directorio elegido. No cubriremos `walk` en este curso, pero es una de las herramientas muy útiles (junto con el submódulo `os.path`) para trabajar con archivos en Python, especialmente si está trabajando con muchos archivos de datos diferentes. inmediatamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "996my40Qav2X"
      },
      "source": [
        "## Archivos CSV\n",
        "\n",
        "Uno de los formatos más simples y comunes para guardar datos es el de valores separados por comas (CSV)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mTpYzuuav2X"
      },
      "outputs": [],
      "source": [
        "with open('./data/csv_sample.txt', 'r') as f:\n",
        "    csv = f.read()\n",
        "\n",
        "print(csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoxpzFNZav2X"
      },
      "source": [
        "Este formato se utiliza a menudo para representar tablas de datos. Por lo general, un CSV tendrá filas (separadas por caracteres de nueva línea, `'\\n'`) y columnas (separadas por comas). Por lo demás, no se diferencian de cualquier otro archivo de texto. Podemos usar el formato especial de un CSV para crear una lista de listas que representen la tabla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhRf-qAlav2X"
      },
      "outputs": [],
      "source": [
        "list_table = []\n",
        "with open('./data/csv_sample.txt', 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        list_table.append(line.strip().split(','))\n",
        "\n",
        "list_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0z0LyiAav2Y"
      },
      "source": [
        "Sin embargo, podemos trabajar con datos tabulares mucho más fácilmente en un Pandas DataFrame. Pandas proporciona un método `read_csv` para leer los datos directamente en un DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYHLK39Yav2Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('./data/csv_sample.txt', index_col=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SMUDxfbav2Y"
      },
      "source": [
        "El método `read_csv` es muy flexible para manejar el formato de diferentes conjuntos de datos. Algunos conjuntos de datos incluirán encabezados de columna, mientras que otros no. Algunos conjuntos de datos incluirán un índice, mientras que otros no. Algunos conjuntos de datos pueden tener valores separados por tabulaciones, punto y coma u otros caracteres en lugar de comas. Hay opciones en el método `read_csv` para tratar con todos estos. Puede leer sobre ellos en la [documentación de Pandas en `read_csv`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). También lo analizaremos más a fondo en el [Cuaderno de Pandas](08_Pandas.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwOVLsNUav2Y"
      },
      "outputs": [],
      "source": [
        "# an example of downloading\n",
        "# and importing real data using `read_csv`\n",
        "\n",
        "if 'factbook.csv' not in os.listdir('./data/'):\n",
        "    !wget -P ./data/ https://perso.telecom-paristech.fr/eagan/class/igr204/data/factbook.csv\n",
        "\n",
        "countries = pd.read_csv('./data/factbook.csv', delimiter=';', skiprows=[1])\n",
        "countries.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1xun92uav2Y"
      },
      "outputs": [],
      "source": [
        "# we can also use pandas to write CSV\n",
        "# using the DataFrame's to_csv method\n",
        "\n",
        "pd.DataFrame({'a': [0, 3, 10], 'b': [True, True, False]}).to_csv('./data/pd_write.csv')\n",
        "\n",
        "pd.read_csv('./data/pd_write.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S00OBWmJav2Z"
      },
      "source": [
        "A veces, un CSV no será perfecto. Por ejemplo, tal vez diferentes filas tengan diferentes números de comas. Esto dificulta la interpretación del contenido del archivo como una tabla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RauiceVNav2Z"
      },
      "outputs": [],
      "source": [
        "# the 3rd line only has 2 \"columns\"\n",
        "\n",
        "!cat ./data/bad_csv.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLkO-Yq5av2Z"
      },
      "outputs": [],
      "source": [
        "# what happens if we try to read this\n",
        "# into a DataFrame using read_csv?\n",
        "\n",
        "pd.read_csv('./data/bad_csv.csv', index_col = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXF3W5Rgav2Z"
      },
      "source": [
        "El método `read_csv` de Pandas hará todo lo posible para construir una tabla a partir de un CSV mal formateado, pero puede cometer errores. Por ejemplo, 54 se interpretó como un nombre en lugar de una edad, porque solo había 2 columnas en esa línea del archivo. Los conjuntos de datos a menudo contienen errores como formato incorrecto, datos faltantes o errores tipográficos.\n",
        "\n",
        "**Pregunta:** ¿Cómo podríamos arreglar el CSV mal formateado para que funcione con `read_csv`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlfFdSI5av2Z"
      },
      "source": [
        "##JSON\n",
        "\n",
        "JSON significa notación de objetos JavaScript. JavaScript es un lenguaje común para crear aplicaciones web y los archivos JSON se utilizan para recopilar y transmitir información entre aplicaciones JavaScript. Como resultado, existe una gran cantidad de datos en Internet en formato de archivo JSON. Por ejemplo, Twitter y Google Maps utilizan JSON.\n",
        "\n",
        "Un archivo JSON es esencialmente una estructura de datos construida a partir de listas y diccionarios anidados. Hagamos nuestro propio ejemplo y luego examinaremos un ejemplo descargado de Internet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK93eATKav2Z"
      },
      "outputs": [],
      "source": [
        "book1 = {'title': 'The Prophet',\n",
        "         'author': 'Khalil Gibran',\n",
        "         'genre': 'poetry',\n",
        "         'tags': ['religion', 'spirituality', 'philosophy', 'Lebanon', 'Arabic', 'Middle East'],\n",
        "         'book_id': '811.19',\n",
        "         'copies': [{'edition_year': 1996,\n",
        "                     'checkouts': 486,\n",
        "                     'borrowed': False},\n",
        "                    {'edition_year': 1996,\n",
        "                     'checkouts': 443,\n",
        "                     'borrowed': False}]\n",
        "         }\n",
        "\n",
        "book2 = {'title': 'The Little Prince',\n",
        "         'author': 'Antoine de Saint-Exupery',\n",
        "         'genre': 'children',\n",
        "         'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
        "         'id': '843.912',\n",
        "         'copies': [{'edition_year': 1983,\n",
        "                     'checkouts': 634,\n",
        "                     'borrowed': True,\n",
        "                     'due_date': '2017/02/02'},\n",
        "                    {'edition_year': 2015,\n",
        "                     'checkouts': 41,\n",
        "                     'borrowed': False}]\n",
        "         }\n",
        "\n",
        "library = [book1, book2]\n",
        "library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrRrCY7jav2Z"
      },
      "source": [
        "Tenemos dos libros en nuestra \"biblioteca\". Ambos libros tienen algunas propiedades comunes: título, autor, identificación y etiquetas. Cada libro puede tener varias etiquetas, por lo que almacenamos esos datos como una lista. Además, puede haber varias copias de cada libro y cada copia también tiene información única, como el año en que se imprimió y cuántas veces se sacó prestado. Tenga en cuenta que si un libro está prestado, también tiene una fecha de vencimiento. Es conveniente almacenar la información sobre las copias múltiples como una lista de diccionarios dentro del diccionario sobre el libro, porque cada copia comparte el mismo título, autor, etc.\n",
        "\n",
        "Esta estructura es típica de los archivos JSON. Tiene la ventaja de reducir la redundancia de datos. Solo almacenamos el autor y el título una vez, aunque haya varias copias del libro. Además, no almacenamos una fecha de vencimiento para las copias que no están prestadas.\n",
        "\n",
        "Si tuviéramos que poner estos datos en una tabla, tendríamos que duplicar mucha información. Además, dado que solo se ha prestado una copia de nuestra biblioteca, también tenemos una columna con muchos datos faltantes.    \n",
        "\n",
        "| index |        title        |          author          |    id    |  genre   |                           tags                            | edition_year | checkouts | borrowed |  due_date  |\n",
        "|:-----:|:-------------------:|:------------------------:|:--------:|:--------:|:--------------------------------------------------------:|:------------:|:---------:|:--------:|:----------:|\n",
        "|   0   |     The Prophet     |     Khalil Gibran        |  811.19  |  poetry  | religion, spirituality, philosophy, Lebanon, Arabic, Middle East |     1996     |    486    |   False  |    Null    |\n",
        "|   1   |     The Prophet     |     Khalil Gibran        |  811.19  |  poetry  | religion, spirituality, philosophy, Lebanon, Arabic, Middle East |     1996     |    443    |   False  |    Null    |\n",
        "|   2   | The Little Prince   | Antoine de Saint-Exupery | 843.912  | children |     fantasy, France, philosophy, illustrated, fable      |     1983     |    634    |   True   | 2017/02/02 |\n",
        "|   3   | The Little Prince   | Antoine de Saint-Exupery | 843.912  | children |     fantasy, France, philosophy, illustrated, fable      |     2015     |     41    |   False  |    Null    |\n",
        "\n",
        "\n",
        "Esto es un gran desperdicio. Dado que los archivos JSON están destinados a compartirse rápidamente a través de Internet, es importante que sean pequeños para reducir la cantidad de recursos necesarios para almacenarlos y transmitirlos.\n",
        "\n",
        "Podemos escribir nuestra `biblioteca` en el disco usando el módulo `json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14iIP1lUav2e"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('./data/library.json', 'w') as f:\n",
        "    json.dump(library, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JtOXh7Aav2e"
      },
      "outputs": [],
      "source": [
        "!cat ./data/library.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LRjOudSav2e"
      },
      "outputs": [],
      "source": [
        "with open('./data/library.json', 'r') as f:\n",
        "    reloaded_library = json.load(f)\n",
        "\n",
        "reloaded_library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6zTthR8av2e"
      },
      "outputs": [],
      "source": [
        "# note that if we loaded it in without JSON\n",
        "# the file would be interpreted as plain text\n",
        "\n",
        "with open('./data/library.json', 'r') as f:\n",
        "    library_string = f.read()\n",
        "\n",
        "# this isn't what we want\n",
        "library_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiEiU21sav2e"
      },
      "outputs": [],
      "source": [
        "# Pandas can also read_json\n",
        "# notice how it constructs the table\n",
        "# does it represent the data well?\n",
        "\n",
        "pd.read_json('./data/library.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sayVvBuTav2e"
      },
      "outputs": [],
      "source": [
        "# and to_json\n",
        "df.to_json('./data/example_df.json')\n",
        "\n",
        "!head ./data/example_df.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si4FQjdsav2f"
      },
      "source": [
        "Podemos descargar archivos JSON de muchas formas. A veces lo descargaremos manualmente, pero también podemos usar `wget` como hicimos en el ejemplo CSV. A menudo nos conectaremos a la API de un sitio web que responderá utilizando JSON.\n",
        "\n",
        "El método `read_json` de Panda es capaz de conectarse directamente a una URL (ya sea la dirección de un archivo JSON o una conexión API) y leer el JSON sin guardar el archivo en nuestro ordenador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJOUYbYqav2f"
      },
      "outputs": [],
      "source": [
        "pd.read_json('https://api.github.com/repos/pydata/pandas/issues?per_page=5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HXzYrq0av2f"
      },
      "source": [
        "## Archivos comprimidos (Gzip)\n",
        "\n",
        "Otra forma de ahorrar almacenamiento y recursos de red es mediante el uso de **compresión**. Muchas veces los conjuntos de datos contendrán patrones que pueden usarse para reducir la cantidad de espacio necesario para almacenar la información.\n",
        "\n",
        "Un ejemplo sencillo es la siguiente lista de números: 10, 10, 10, 2, 3, 3, 3, 3, 3, 50, 50, 1, 1, 50, 10, 10, 10, 10\n",
        "\n",
        "En lugar de escribir la lista completa de números (18 enteros), podemos representar la misma información con sólo 14 números: (3, 10), (1, 2), (5, 3), (2, 50), ( 2, 1), (1, 50), (4, 10)\n",
        "\n",
        "Aquí el primer número de cada par es el número de repeticiones y el segundo número del par es el valor real. Hemos reducido con éxito la cantidad de números que necesitamos para representar los mismos datos. La mayoría de las formas de compresión utilizan una idea similar, aunque las implementaciones reales suelen ser más complejas.\n",
        "\n",
        "En el mundo de la ciencia de datos, la compresión más común es Gzip (que utiliza el [algoritmo deflate](http://www.infinitepartitions.com/art001.html)). Los archivos gzip terminan con la extensión `.gz`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lUDyK6jav2f"
      },
      "outputs": [],
      "source": [
        "!wget -P ./data/ https://archive.org/stream/TheEpicofGilgamesh_201606/eog_djvu.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-iaF28dav2f"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "\n",
        "with open('./data/eog_djvu.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "with gzip.open('./data/eog_djvu.txt.gz', 'wb') as f:\n",
        "    f.write(bytes(text, encoding = 'utf-8'))\n",
        "\n",
        "!ls -lh ./data/eog*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmsJGDeZav2f"
      },
      "source": [
        "¡Pudimos comprimir el texto de La Epopeya de Gilgamesh a un tercio de su tamaño original! Recuerde que la compresión depende de los patrones de los datos. El lenguaje tiene muchos patrones, pero ¿qué pasaría si mezclamos todas las letras del texto?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlHBrBKxav2f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "with gzip.open('./data/eog_djvu_scrambled.txt.gz', 'wb') as f:\n",
        "    f.write(np.random.permutation(list(text)))\n",
        "\n",
        "!ls -lh ./data/eog*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6uq-ZnAav2g"
      },
      "source": [
        "La versión codificada sólo se comprimió a dos tercios del tamaño del original. La compresión no funcionará muy bien en datos aleatorios. La compresión tampoco funciona muy bien en datos que ya son pequeños."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j1LDIBbav2g"
      },
      "outputs": [],
      "source": [
        "short_text = 'Hello'\n",
        "\n",
        "with open('./data/short_text.txt', 'w') as f:\n",
        "    f.write(short_text)\n",
        "\n",
        "with gzip.open('./data/short_text.txt.gz', 'wb') as f:\n",
        "    f.write(bytes(short_text, encoding='utf-8'))\n",
        "\n",
        "!ls -lh ./data/short_text*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eww9rOlCav2g"
      },
      "source": [
        "¡El archivo comprimido es más grande que el texto sin formato! Esto se debe a que el archivo comprimido incluye un encabezado, que ocupa una pequeña cantidad de espacio adicional. Además, dado que el texto es tan corto, no es posible utilizar patrones para representar el texto de manera más eficiente. Por lo tanto, normalmente reservamos la compresión para archivos grandes.\n",
        "\n",
        "Es posible que hayas notado que cuando escribimos archivos Gzip, hemos estado usando una bandera `'wb'` en lugar de una bandera simple `'w'`. Esto se debe a que Gzip no es texto sin formato. Al comprimir el archivo escribimos archivos _binarios_. Los archivos no se pueden leer como texto sin formato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79pyVBB-av2g"
      },
      "outputs": [],
      "source": [
        "# we have to uncompress the file\n",
        "# before we can read it\n",
        "\n",
        "!cat ./data/short_text.txt.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzocoXEjav2g"
      },
      "source": [
        "Sólo debemos usar `'w'` para archivos de texto sin formato (que incluyen CSV y JSON). El uso de `'w'` en lugar de `'wb'` para archivos Gzip u otros archivos que no sean texto plano (por ejemplo, imágenes) podría dañar el archivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEQ8wIzAav2h"
      },
      "source": [
        "## Serialización (`pickle`)\n",
        "\n",
        "A menudo querremos guardar nuestro trabajo en Python y volver a él más tarde. Sin embargo, ese trabajo podría ser un modelo de aprendizaje automático o algún otro objeto complejo en Python. ¿Cómo guardamos objetos complejos de Python? Python tiene un módulo para este propósito llamado `pickle`. Podemos usar `pickle` para escribir un archivo binario que contenga toda la información sobre un objeto Python. Luego podemos cargar ese archivo pickle y reconstruir el objeto en Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yi_3BBfav2i"
      },
      "outputs": [],
      "source": [
        "pickle_example = ['hello', {'a': 23, 'b': True}, (1, 2, 3), [['dogs', 'cats'], None]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBjcC1jZav2i"
      },
      "outputs": [],
      "source": [
        "%%expect_exception TypeError\n",
        "\n",
        "# we can't save this as text\n",
        "with open('./data/pickle_example.txt', 'w') as f:\n",
        "    f.write(pickle_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRuJFnwZav2i"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# we can save it as a pickle\n",
        "with open('./data/pickle_example.pkl', 'wb') as f:\n",
        "    pickle.dump(pickle_example, f)\n",
        "\n",
        "with open('./data/pickle_example.pkl', 'rb') as f:\n",
        "    reloaded_example = pickle.load(f)\n",
        "\n",
        "reloaded_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g08MAa5Vav2i"
      },
      "outputs": [],
      "source": [
        "# the reloaded example is the same as the original\n",
        "\n",
        "reloaded_example == pickle_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cceABNhlav2i"
      },
      "source": [
        "Pickle es una herramienta importante para los científicos de datos. El procesamiento de datos y el entrenamiento de modelos de aprendizaje automático pueden llevar mucho tiempo y es útil para guardar puntos de control.\n",
        "\n",
        "Pandas también tiene métodos `to_pickle` y `read_pickle`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsDzkgMEav2j"
      },
      "source": [
        "## Formatos de archivo NumPy\n",
        "\n",
        "NumPy también tiene métodos para guardar y cargar datos. Son fáciles de usar. Puede encontrar estos cuando trabaje con ciertas bibliotecas de aprendizaje automático que requieren que los datos se almacenen en matrices NumPy. Las matrices NumPy también se utilizan a menudo cuando se trabaja con datos de imágenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3y17RgRav2j"
      },
      "outputs": [],
      "source": [
        "sample_array = np.random.random((4, 4))\n",
        "print(sample_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gefb-jB9av2j"
      },
      "outputs": [],
      "source": [
        "# to save as plain text\n",
        "np.savetxt('./data/sample_array.txt', sample_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK2ZyNuEav2j"
      },
      "outputs": [],
      "source": [
        "!cat ./data/sample_array.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEHXwBmFav2j"
      },
      "outputs": [],
      "source": [
        "print(np.loadtxt('./data/sample_array.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmKHGkmEav2j"
      },
      "outputs": [],
      "source": [
        "# to save as compressed binary\n",
        "np.save('./data/sample_array.npy', sample_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ76xkEGav2j"
      },
      "outputs": [],
      "source": [
        "!cat ./data/sample_array.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OSNQcchav2k"
      },
      "outputs": [],
      "source": [
        "print(np.load('./data/sample_array.npy'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_r8CZUCav2k"
      },
      "source": [
        "## Temas utilizados por no discutidos:\n",
        "- Comandos BASH (!)\n",
        "-`wget`\n",
        "- `str.split()`\n",
        "- API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPWPsyhAav2k"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "nbclean": true,
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
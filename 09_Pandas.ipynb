{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubuntu/uaa-417-sistemas-de-gestion-de-bases-de-datos-avanzados/blob/main/08_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iwvcXoZdyG2"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "matplotlib.rcParams['savefig.dpi'] = 144"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnk45ck6dyG3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install expectexception\n",
        "import expectexception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MjGQVbsdyG3"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJfjOU6TdyG3"
      },
      "source": [
        "# Pandas\n",
        "\n",
        "<!-- requirement: data/yelp.json.gz -->\n",
        "<!-- requirement: data/PEP_2016_PEPANNRES.csv -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PiK8efsdyG4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u18ogGZsdyG4"
      },
      "source": [
        "Presentamos el módulo Pandas y el objeto DataFrame en la lección sobre [módulos básicos de ciencia de datos](07_Modulos_Basicos_DS.ipynb). Aprendimos a construir un DataFrame, agregar datos, recuperar datos y [leer y escribir en disco de forma básica](06_IO.ipynb). Ahora exploraremos el objeto DataFrame y sus potentes métodos de análisis con más profundidad.\n",
        "\n",
        "Trabajaremos con un conjunto de datos del sitio de reseñas en línea, Yelp. El archivo se almacena como un archivo JSON comprimido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxbsyR2ox5Ar"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!mkdir data\n",
        "!wget -P ./data/ https://raw.githubusercontent.com/rubuntu/uaa-417-sistemas-de-gestion-de-bases-de-datos-avanzados/main/data/yelp.json.gz\n",
        "!wget -P ./data/ https://raw.githubusercontent.com/rubuntu/uaa-417-sistemas-de-gestion-de-bases-de-datos-avanzados/main/data/PEP_2016_PEPANNRES.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhVwAbt6dyG4"
      },
      "outputs": [],
      "source": [
        "!ls -lh ./data/yelp.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb2da7Z_dyG4"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import json\n",
        "\n",
        "with gzip.open('./data/yelp.json.gz', 'r') as f:\n",
        "    yelp_data = [json.loads(line) for line in f]\n",
        "\n",
        "yelp_df = pd.DataFrame(yelp_data)\n",
        "yelp_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9Q7UQZ1dyG4"
      },
      "source": [
        "## Pandas DataFrame y Series\n",
        "\n",
        "El DataFrame de Pandas es un objeto altamente estructurado. Cada fila corresponde a una entidad física o un evento. Pensamos que toda la información de una fila determinada se refiere a un objeto (por ejemplo, una empresa). Cada columna contiene un tipo de datos, tanto semánticamente (por ejemplo, nombres, cantidad de reseñas, calificaciones con estrellas) como sintácticamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAYKFfKedyG4"
      },
      "outputs": [],
      "source": [
        "yelp_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uadAdMhddyG4"
      },
      "source": [
        "Podemos hacer referencia a las columnas por nombre, como lo haríamos con un `dict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOha17KmdyG4"
      },
      "outputs": [],
      "source": [
        "yelp_df['city'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oObb9Rk9dyG4"
      },
      "outputs": [],
      "source": [
        "type(yelp_df['city'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saRkgbY9dyG4"
      },
      "source": [
        "Una columna individual es una «Serie» de Pandas. Una «Serie» tiene un «nombre» y un «dtype» (similar a una matriz NumPy). Un «DataFrame» es esencialmente un «dict» de objetos «Serie». La «Serie» tiene un atributo «índice», que etiqueta las filas. El índice es esencialmente un conjunto de claves para hacer referencia a las filas. Podemos tener un índice compuesto de números, cadenas, marcas de tiempo o cualquier objeto de Python que se pueda convertir en hash. El índice también tendrá un tipo homogéneo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvS2tf2EdyG4"
      },
      "outputs": [],
      "source": [
        "yelp_df['city'].index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGm0xFCddyG4"
      },
      "source": [
        "El `DataFrame` tiene un `índice` dado por la unión de los índices de su `Series` constituyente (exploraremos esto más adelante con más detalle). Dado que un `DataFrame` es un `dict` de `Series`, podemos seleccionar una columna y luego una fila usando la notación de corchetes, pero no a la inversa (sin embargo, el método `loc` soluciona este problema)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59cow8XydyG4"
      },
      "outputs": [],
      "source": [
        "# this works\n",
        "yelp_df['city'][100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TAL6u4bdyG4"
      },
      "outputs": [],
      "source": [
        "%%expect_exception KeyError\n",
        "\n",
        "# this doesn't\n",
        "yelp_df[100]['city']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eevEISh7dyG4"
      },
      "outputs": [],
      "source": [
        "yelp_df.loc[100, 'city']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIF4gI5ldyG5"
      },
      "source": [
        "Comprender la estructura subyacente del objeto `DataFrame` como un `dict` de `Series` le ayudará a evitar errores y le ayudará a pensar en cómo debería comportarse el `DataFrame` cuando comencemos a realizar análisis más complicados.\n",
        "\n",
        "Podemos _agregar_ datos en un `DataFrame` utilizando métodos como `mean`, `sum`, `count` y `std`. Para ver una colección de estadísticas resumidas para cada columna, podemos utilizar el método `describe`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W9utoAhdyG5"
      },
      "outputs": [],
      "source": [
        "yelp_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uRGlOP7dyG5"
      },
      "source": [
        "La utilidad de un DataFrame proviene de su capacidad para dividir los datos en grupos, utilizando el método `groupby`, y luego realizar agregaciones personalizadas utilizando el método `apply` o `agregate`. Este proceso de dividir los datos en grupos, aplicar una agregación y luego recopilar los resultados se [analiza en detalle en la documentación de Pandas](https://pandas.pydata.org/pandas-docs/stable/groupby.html), y es uno de los principales objetivos de este cuaderno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H94GNVQ1dyG5"
      },
      "source": [
        "## Construcción de DataFrame\n",
        "\n",
        "Dado que un `DataFrame` es un `dict` de `Series`, la forma natural de construir un `DataFrame` es utilizar un `dict` de objetos similares a `Series`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC3SO84WdyG5"
      },
      "outputs": [],
      "source": [
        "from string import ascii_letters, digits\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC1GnjX24xRo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from string import ascii_letters, digits\n",
        "import datetime\n",
        "\n",
        "usernames = ['alice36', 'bob_smith', 'eve']\n",
        "\n",
        "passwords = [''.join(np.random.choice(list(ascii_letters + digits), 8)) for x in range(3)]\n",
        "creation_dates = [datetime.datetime.now().date() - datetime.timedelta(days=int(x)) for x in np.random.randint(0, 1500, 3)] # Cast numpy.int64 to int using int(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9wdkx9r0SpJ"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from string import ascii_letters, digits\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "usernames = ['alice36', 'bob_smith', 'eve']\n",
        "\n",
        "passwords = [''.join(np.random.choice(list(ascii_letters + digits), 8)) for x in range(3)]\n",
        "creation_dates = [datetime.datetime.now().date() - datetime.timedelta(days=int(x)) for x in np.random.randint(0, 1500, 3)] # Cast numpy.int64 to int using int(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8vUhil9dyG5"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'username': usernames, 'password': passwords, 'date-created': creation_dates})\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hkYx1m0dyG5"
      },
      "source": [
        "El `DataFrame` también está estrechamente relacionado con el `ndarray` de NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao3rIH0ldyG5"
      },
      "outputs": [],
      "source": [
        "random_data = np.random.random((4,3))\n",
        "random_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQyng2ECdyG5"
      },
      "outputs": [],
      "source": [
        "df_random = pd.DataFrame(random_data, columns=['a', 'b', 'c'])\n",
        "df_random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntwL6NxvdyG5"
      },
      "source": [
        "Para agregar una nueva columna o fila, simplemente usamos una asignación similar a \"dict\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGsX7Q-PdyG5"
      },
      "outputs": [],
      "source": [
        "emails = ['alice.chan@gmail.com', 'bwsmith1983@gmail.com', 'fakemail123@yahoo.com']\n",
        "df['email'] = emails\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQVmR3KkdyG5"
      },
      "outputs": [],
      "source": [
        "# loc references index value, NOT position\n",
        "# for position use iloc\n",
        "df.loc[3] = ['2015-01-29', '38uzFJ1n', 'melvintherobot', 'moviesrgood@moviesrgood.com']\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIqJkD-TdyG5"
      },
      "source": [
        "También podemos eliminar columnas y filas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8UDD7ykdyG5"
      },
      "outputs": [],
      "source": [
        "df.drop(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeUPNrEZdyG5"
      },
      "outputs": [],
      "source": [
        "# to drop a column, need axis=1\n",
        "df.drop('email', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMovSvEpdyG6"
      },
      "source": [
        "Observe que cuando eliminamos la columna `'email'`, la fila en el índice 3 estaba en el `DataFrame`, ¡a pesar de que recién la eliminamos! La mayoría de las operaciones en Pandas devuelven una _copia_ del `DataFrame`, en lugar de modificar el objeto `DataFrame` en sí. Por lo tanto, para alterar permanentemente el `DataFrame`, necesitamos reasignar la variable `df` o usar la palabra clave `inplace`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GUCmHchdyG6"
      },
      "outputs": [],
      "source": [
        "df.drop(3, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovPCioO8dyG6"
      },
      "source": [
        "Dado que los nombres de las columnas y del índice son importantes para interactuar con los datos en el DataFrame, debemos asegurarnos de configurarlos con valores útiles. Podemos hacerlo durante la construcción o después."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wILT-GsndyG6"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'email': emails, 'password': passwords, 'date-created': creation_dates}, index=usernames)\n",
        "df.index.name = 'users' # it can be helpful to give the index a name\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt9MU2UMdyG6"
      },
      "outputs": [],
      "source": [
        "# alternatively\n",
        "df = pd.DataFrame(zip(usernames, emails, passwords, creation_dates))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92Tg5oHtdyG6"
      },
      "outputs": [],
      "source": [
        "df.columns = ['username', 'email', 'password', 'date-created']\n",
        "df.set_index('username', inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv-lEGP6dyG7"
      },
      "outputs": [],
      "source": [
        "# to reset index to a column\n",
        "df.reset_index(inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stDxFA8udyG7"
      },
      "source": [
        "Podemos tener varios niveles en un índice. Descubriremos que, para algunos conjuntos de datos, es necesario tener varios niveles en el índice para identificar de forma única una fila."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGcd_M6odyG7"
      },
      "outputs": [],
      "source": [
        "df.set_index(['username', 'email'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6dLPo2dyG7"
      },
      "source": [
        "### Lectura de datos de un archivo\n",
        "\n",
        "También podemos construir un DataFrame utilizando datos almacenados en un archivo o recibidos desde un sitio web. La fuente de datos puede ser [JSON](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html), [HTML](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_html.html), [CSV](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html#pandas.read_csv), [Excel](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html), [Python pickle](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_pickle.html), o incluso una [conexión de base de datos](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql.html). Cada formato tendrá sus propios métodos para leer y escribir datos que toman diferentes argumentos. Los argumentos de estos métodos generalmente dependen del formato particular del archivo. Por ejemplo, los valores en un CSV pueden estar separados por comas o punto y coma, puede tener un encabezado o no.\n",
        "\n",
        "El método `read_csv` tiene que lidiar con la mayoría de las posibilidades de formato, por lo que exploraremos ese método con algunos ejemplos. Intente aplicar estas ideas cuando trabaje con otros formatos de archivo, pero tenga en cuenta que cada formato y método de lectura es diferente. Siempre consulte [la documentación de Pandas](http://pandas.pydata.org/pandas-docs/stable/io.html) cuando tenga problemas con la lectura o escritura de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68KcYidzdyG7"
      },
      "outputs": [],
      "source": [
        "csv = [','.join(map(lambda x: str(x), row)) for row in np.vstack([df.columns, df])]\n",
        "with open('./data/read_csv_example.csv', 'w') as f:\n",
        "    [f.write(line + '\\n') for line in csv]\n",
        "\n",
        "!cat ./data/read_csv_example.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2i0Z5KrmdyG7"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('./data/read_csv_example.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8r17ZrkdyG7"
      },
      "outputs": [],
      "source": [
        "# we can also set an index from the data\n",
        "pd.read_csv('./data/read_csv_example.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUGb40F_dyG7"
      },
      "outputs": [],
      "source": [
        "# what if our data had no header?\n",
        "with open('./data/read_csv_noheader_example.csv', 'w') as f:\n",
        "    [f.write(line + '\\n') for i, line in enumerate(csv) if i != 0]\n",
        "\n",
        "!cat ./data/read_csv_noheader_example.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R6c8WNIdyG7"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('./data/read_csv_noheader_example.csv', names=['username', 'email', 'password', 'date-created'], header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0JouGm1dyG7"
      },
      "outputs": [],
      "source": [
        "# what if our data was tab-delimited?\n",
        "tsv = ['\\t'.join(map(lambda x: str(x), row)) for row in np.vstack([df.columns, df])]\n",
        "with open('./data/read_csv_example.tsv', 'w') as f:\n",
        "    [f.write(line + '\\n') for line in tsv]\n",
        "\n",
        "!cat ./data/read_csv_example.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey79qvQxdyG7"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('./data/read_csv_example.tsv', delimiter='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvEx4fDNdyG7"
      },
      "source": [
        "Incluso dentro de un único formato de archivo, los datos se pueden organizar y formatear de muchas maneras. Estos han sido solo algunos ejemplos de los tipos de argumentos que podría necesitar usar con `read_csv` para leer datos en un DataFrame de manera organizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldRgNn-3dyG7"
      },
      "source": [
        "## Filtrado de DataFrames\n",
        "\n",
        "Una de las potentes herramientas analíticas de Pandas DataFrame es su sintaxis para filtrar datos. A menudo, solo queremos trabajar con un determinado subconjunto de nuestros datos en función de algunos criterios. Veamos nuestros datos de Yelp como ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47VG6HfxdyG7"
      },
      "outputs": [],
      "source": [
        "yelp_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3__jz348dyG7"
      },
      "source": [
        "Vemos que el conjunto de datos de Yelp tiene una columna de \"estado\". Si solo nos interesan las empresas de Arizona (AZ), podemos filtrar el DataFrame y seleccionar solo esos datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBq5dHRadyG8"
      },
      "outputs": [],
      "source": [
        "az_yelp_df = yelp_df[yelp_df['state'] == 'AZ']\n",
        "az_yelp_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXX4jWq0dyG8"
      },
      "outputs": [],
      "source": [
        "az_yelp_df['state'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guFeG75RdyG8"
      },
      "source": [
        "Podemos combinar criterios mediante lógica. ¿Qué pasa si solo nos interesan las empresas con más de 10 reseñas en Arizona?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifCythj2dyG8"
      },
      "outputs": [],
      "source": [
        "yelp_df[(yelp_df['state'] == 'AZ') & (yelp_df['review_count'] > 10)].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX2a7m5MdyG8"
      },
      "source": [
        "¿Cómo funciona este filtrado?\n",
        "\n",
        "Cuando escribimos `yelp_df['state'] == 'AZ'`, Pandas selecciona la columna `'state'` y comprueba si cada fila es `'AZ'`. Si es así, esa fila se marca como `'True``, y si no, se marca como `'False``. Así es como normalmente esperaríamos que funcionara un condicional, solo que ahora se aplica a una `Series` completa de Pandas. Terminamos con una `Series` de Pandas de variables booleanas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSZV87-MdyG8"
      },
      "outputs": [],
      "source": [
        "(yelp_df['state'] == 'AZ').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THaT90szdyG8"
      },
      "source": [
        "Podemos utilizar una 'Serie' (o cualquier objeto similar) de variables booleanas para indexar el DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBsN8Wc3dyG8"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hjh9pSCdyG8"
      },
      "outputs": [],
      "source": [
        "df[[True, False, True]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkpAUtm8dyG8"
      },
      "source": [
        "Esto nos permite filtrar un DataFrame usando expresiones lógicas idiomáticas como `yelp_df['review_count'] > 10`.\n",
        "\n",
        "Como otro ejemplo, consideremos la columna `'open'`, que es un indicador `True`/`False` que indica si una empresa está abierta. Esta también es una `Series` booleana de Pandas, por lo que podemos usarla directamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSozVpUFdyG8"
      },
      "outputs": [],
      "source": [
        "# the open businesses\n",
        "yelp_df[yelp_df['open']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTFlxtsLdyG8"
      },
      "outputs": [],
      "source": [
        "# the closed businesses\n",
        "yelp_df[~yelp_df['open']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg3lU9t6dyG8"
      },
      "source": [
        "Observa que en una expresión anterior escribimos `(yelp_df['state'] == 'AZ') & (yelp_df['review_count'] > 10)`. Normalmente, en Python usamos la palabra `and` cuando trabajamos con lógica. En Pandas, tenemos que usar operadores lógicos _bit a bit_; todo lo que es importante saber son las siguientes equivalencias:\n",
        "\n",
        "`~` = `not`    \n",
        "`&` = `and`    \n",
        "`|` = `or`    \n",
        "\n",
        "También podemos usar las [operaciones de cadena](https://pandas.pydata.org/pandas-docs/stable/text.html) integradas de Panda para hacer coincidencias de patrones. Por ejemplo, hay muchas empresas en Las Vegas en nuestro conjunto de datos. Sin embargo, también hay empresas en 'Las Vegas East' y 'South Las Vegas'. Para obtener todas las empresas de Las Vegas, podría hacer lo siguiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y26bVpHldyG8"
      },
      "outputs": [],
      "source": [
        "vegas_yelp_df = yelp_df[yelp_df['city'].str.contains('Vegas')]\n",
        "vegas_yelp_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J24jokQOdyG8"
      },
      "outputs": [],
      "source": [
        "vegas_yelp_df['city'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15Dtjjg7dyG8"
      },
      "source": [
        "## Aplicación de funciones y agregación de datos\n",
        "\n",
        "Para analizar los datos en el marco de datos, necesitaremos poder aplicarles funciones. Pandas ya tiene muchas funciones matemáticas integradas, y los marcos de datos y las series se pueden pasar a funciones de NumPy (ya que se comportan como matrices de NumPy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wpv7aZ0ldyG8"
      },
      "outputs": [],
      "source": [
        "log_review_count = np.log(yelp_df['review_count'])\n",
        "print(log_review_count.head())\n",
        "print(log_review_count.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4zGytZVdyG9"
      },
      "outputs": [],
      "source": [
        "mean_review_count = yelp_df['review_count'].mean()\n",
        "print(mean_review_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y73q9lFdyG9"
      },
      "source": [
        "En el primer ejemplo, tomamos el _logaritmo_ del recuento de reseñas de cada negocio. En el segundo caso, calculamos el recuento de reseñas promedio de todos los negocios. En el primer caso, terminamos con un número para cada negocio. _Transformamos_ el recuento de reseñas utilizando el logaritmo. En el segundo caso, _resumimos_ el recuento de reseñas de todos los negocios en un solo número. Este resumen es una forma de _agregación de datos_, en la que tomamos muchos puntos de datos y los combinamos en una representación más pequeña. Las funciones que aplicamos a nuestros conjuntos de datos estarán en la categoría de **transformaciones** o **agregaciones**.\n",
        "\n",
        "A veces necesitaremos transformar nuestros datos para que sean utilizables. Por ejemplo, en la columna `'atributos'` de nuestro DataFrame, tenemos un `dict` para cada negocio que enumera todas sus propiedades. Si quisiera encontrar un restaurante que ofrezca servicio de entrega, me resultaría difícil filtrar el DataFrame, aunque esa información esté en la columna `'atributos'`. Primero, necesito transformar el `dict` en algo más útil."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NwWiZpHdyG9"
      },
      "outputs": [],
      "source": [
        "def get_delivery_attr(attr_dict):\n",
        "    return attr_dict.get('Delivery')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvgjJzcDdyG9"
      },
      "source": [
        "Si le damos a esta función un `dict` de la columna `'attributes'`, buscará la clave `'Delivery'`. Si encuentra esa clave, devolverá el valor. Si no encuentra la clave, devolverá ninguno."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD6xSpDidyG9"
      },
      "outputs": [],
      "source": [
        "print(get_delivery_attr(yelp_df.loc[0, 'attributes']))\n",
        "print(get_delivery_attr(yelp_df.loc[1, 'attributes']))\n",
        "print(get_delivery_attr(yelp_df.loc[2, 'attributes']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz_4aHeqdyG9"
      },
      "source": [
        "Podríamos iterar sobre las filas de `yelp_df['attributes']` para obtener todos los valores, pero hay una mejor manera. DataFrames y Series tienen un método `apply` que nos permite aplicar nuestra función a todo el conjunto de datos a la vez, como hicimos antes con `np.log`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3xnmml5dyG9"
      },
      "outputs": [],
      "source": [
        "delivery_attr = yelp_df['attributes'].apply(get_delivery_attr)\n",
        "delivery_attr.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8zm6UlfdyG9"
      },
      "source": [
        "Podemos crear una nueva columna en nuestro DataFrame con esta información transformada (y útil)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDPGML93dyG9"
      },
      "outputs": [],
      "source": [
        "yelp_df['delivery'] = delivery_attr\n",
        "\n",
        "# to find businesses that deliver\n",
        "yelp_df[yelp_df['delivery'].fillna(False)].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjIvpdf0dyG9"
      },
      "source": [
        "Es menos común (aunque posible) usar `apply` en un DataFrame completo en lugar de solo en una columna. Dado que un DataFrame puede contener muchos tipos de datos, normalmente no querremos aplicar la misma transformación o agregación en todas las columnas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcboRGYidyG9"
      },
      "source": [
        "## Agregación de datos con `groupby`\n",
        "\n",
        "La agregación de datos es un término [_sobrecargado_](https://en.wikipedia.org/wiki/Function_overloading). Se refiere tanto al resumen de datos (como se mencionó anteriormente) como a la combinación de diferentes conjuntos de datos.\n",
        "\n",
        "Con nuestros datos de Yelp, podríamos estar interesados ​​en comparar las calificaciones de estrellas de las empresas en diferentes ciudades. Podríamos calcular la calificación de estrellas promedio para cada ciudad, y esto nos permitiría compararlas fácilmente. Primero tendríamos que dividir nuestros datos por ciudad, calcular la media para cada ciudad y luego combinarlos nuevamente al final. Este procedimiento se conoce como [split-apply-combine](https://pandas.pydata.org/pandas-docs/stable/groupby.html) y es un ejemplo clásico de agregación de datos (en el sentido tanto de resumir datos como de combinar diferentes conjuntos de datos).\n",
        "\n",
        "Logramos la división y la recombinación utilizando el método `groupby`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yjv9kY6sdyG9"
      },
      "outputs": [],
      "source": [
        "stars_by_city = yelp_df.groupby('city')['stars'].mean()\n",
        "stars_by_city.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOrh6ANSdyG9"
      },
      "source": [
        "También podemos aplicar varias funciones a la vez. Puede resultar útil conocer la desviación estándar de las calificaciones con estrellas, la cantidad total de reseñas y también el recuento de empresas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7vkehB177eg"
      },
      "outputs": [],
      "source": [
        "agg_by_city = yelp_df.groupby('city').agg(\n",
        "    mean_stars=('stars', 'mean'),\n",
        "    std_stars=('stars', 'std'),\n",
        "    total_reviews=('review_count', 'sum'),\n",
        "    total_businesses=('business_id', 'count')\n",
        ")\n",
        "\n",
        "agg_by_city.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki1cofCodyG9"
      },
      "source": [
        "¿Cómo funciona esto? ¿Qué hace `groupby`? Comencemos por inspeccionar el resultado de `groupby`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rps3RVeF-PeA"
      },
      "source": [
        "Vamos a desglosar paso a paso cómo funciona el código:\n",
        "\n",
        "### 1. **`yelp_df.groupby('city')`**:\n",
        "   - **Propósito**: Agrupar el DataFrame `yelp_df` por la columna `'city'`. Esto significa que todas las filas del DataFrame que tengan el mismo valor en la columna `'city'` se agrupan en un solo conjunto.\n",
        "   - **Resultado**: Crea un objeto de grupo (`groupby`) que organiza los datos por ciudad. Esto no realiza ninguna operación sobre los datos aún, pero permite realizar operaciones agregadas sobre cada ciudad más adelante.\n",
        "\n",
        "### 2. **`.agg()`**:\n",
        "   - **Propósito**: Aplicar funciones de agregación (como `mean`, `std`, `sum`, etc.) a las columnas específicas de cada grupo (en este caso, cada ciudad).\n",
        "   - **Formato**:\n",
        "     ```python\n",
        "     .agg(\n",
        "         nuevo_nombre_columna=('columna_original', 'función_agrupada')\n",
        "     )\n",
        "     ```\n",
        "     Aquí, se especifica un nuevo nombre para la columna resultante seguido por una tupla con el nombre de la columna sobre la que se aplica la función y la función misma.\n",
        "\n",
        "### 3. **Agregaciones dentro de `agg()`**:\n",
        "   Dentro del método `agg()`, se especifican las operaciones a realizar para cada columna:\n",
        "   \n",
        "   - **`mean_stars=('stars', 'mean')`**:\n",
        "     - **Propósito**: Calcula el promedio de la columna `'stars'` (puntuación) para cada ciudad.\n",
        "     - **Resultado**: Para cada ciudad, se genera una nueva columna en el resultado llamada `mean_stars`, que contiene la media de las puntuaciones (`'stars'`) para esa ciudad.\n",
        "\n",
        "   - **`std_stars=('stars', 'std')`**:\n",
        "     - **Propósito**: Calcula la desviación estándar de la columna `'stars'` para cada ciudad.\n",
        "     - **Resultado**: Se genera una columna llamada `std_stars` que contiene la desviación estándar de las puntuaciones para cada ciudad.\n",
        "\n",
        "   - **`total_reviews=('review_count', 'sum')`**:\n",
        "     - **Propósito**: Suma todos los valores de la columna `'review_count'` para cada ciudad, lo que da el número total de reseñas para esa ciudad.\n",
        "     - **Resultado**: Se genera una columna llamada `total_reviews`, que contiene la suma de todas las reseñas para esa ciudad.\n",
        "\n",
        "   - **`total_businesses=('business_id', 'count')`**:\n",
        "     - **Propósito**: Cuenta cuántas filas (negocios) hay en cada ciudad. Esto se hace contando el número de veces que aparece `'business_id'` en cada grupo.\n",
        "     - **Resultado**: Se genera una columna llamada `total_businesses`, que contiene el número total de negocios en cada ciudad.\n",
        "\n",
        "### 4. **`agg_by_city.head()`**:\n",
        "   - **Propósito**: Mostrar las primeras 5 filas del DataFrame resultante `agg_by_city` que contiene los resultados de las agregaciones.\n",
        "   - **Resultado**: Imprime las primeras 5 ciudades junto con las columnas calculadas: `mean_stars`, `std_stars`, `total_reviews`, y `total_businesses`.\n",
        "\n",
        "### Resumen del resultado:\n",
        "- El DataFrame final `agg_by_city` contiene una fila por cada ciudad con las siguientes columnas:\n",
        "  - **`mean_stars`**: Promedio de puntuaciones (`'stars'`) para esa ciudad.\n",
        "  - **`std_stars`**: Desviación estándar de las puntuaciones.\n",
        "  - **`total_reviews`**: Total de reseñas para los negocios de esa ciudad.\n",
        "  - **`total_businesses`**: Cantidad de negocios registrados en esa ciudad.\n",
        "\n",
        "Este enfoque te permite resumir y obtener estadísticas de varias columnas en función de los grupos creados por la columna `'city'`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlLhrq0wdyG-"
      },
      "source": [
        "## Ordenación\n",
        "\n",
        "Aunque el DataFrame se comporta de forma similar a un `dict` en muchos sentidos, también está ordenado. Por lo tanto, podemos ordenar los datos que contiene. Pandas ofrece dos métodos de ordenación, `sort_values` y `sort_index`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20CM9NsedyG-"
      },
      "outputs": [],
      "source": [
        "yelp_df.sort_values('stars').head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxJnTpV1dyG-"
      },
      "outputs": [],
      "source": [
        "yelp_df.set_index('business_id').sort_index().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr8U7TzXdyG-"
      },
      "source": [
        "No olvide que la mayoría de las operaciones de Pandas devuelven una copia del DataFrame y no actualizan el DataFrame en su lugar (¡a menos que se lo indiquemos!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz8fS4EKdyG-"
      },
      "source": [
        "## Uniendo data sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz4vZ4wndyG-"
      },
      "source": [
        "A menudo, querremos ampliar un conjunto de datos con datos de otro. Por ejemplo, las empresas de las grandes ciudades probablemente obtengan más reseñas que las de las ciudades pequeñas. Podría ser útil escalar el recuento de reseñas según la población de la ciudad. Para ello, necesitaremos añadir datos de población a los datos de Yelp. Podemos obtener datos de población del censo de EE. UU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6d1yvwZdyG-"
      },
      "outputs": [],
      "source": [
        "census = pd.read_csv('./data/PEP_2016_PEPANNRES.csv', skiprows=[1])\n",
        "\n",
        "census.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4MS64jadyG-"
      },
      "outputs": [],
      "source": [
        "# construct city & state fields\n",
        "census['city'] = census['GEO.display-label'].apply(lambda x: x.split(', ')[0])\n",
        "census['state'] = census['GEO.display-label'].apply(lambda x: x.split(', ')[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCJ93VVvdyG-"
      },
      "outputs": [],
      "source": [
        "# convert state names to abbreviations\n",
        "\n",
        "print(census['state'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6kALU1JdyG-"
      },
      "outputs": [],
      "source": [
        "state_abbr = dict(zip(census['state'].unique(), ['CT', 'IL', 'IN', 'KS', 'ME', 'MA', 'MI', 'MN', 'MO', 'NE', 'NH', 'NJ', 'NY', 'ND', 'OH', 'PA', 'RI', 'SD', 'VT', 'WI']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp9aS2BjdyG-"
      },
      "outputs": [],
      "source": [
        "census['state'] = census['state'].replace(state_abbr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64gD3w5mdyG-"
      },
      "outputs": [],
      "source": [
        "# remove last word (e.g. 'city', 'town', township', 'borough', 'village') from city names\n",
        "\n",
        "census['city'] = census['city'].apply(lambda x: ' '.join(x.split(' ')[:-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88LcBe9OdyG-"
      },
      "outputs": [],
      "source": [
        "merged_df = yelp_df.merge(census, on=['state', 'city'])\n",
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBksn7INdyG-"
      },
      "source": [
        "La función `merge` examina las columnas `'state'` y `'city'` de `yelp_df` y `census` e intenta hacer coincidir las filas que comparten valores. Cuando se encuentra una coincidencia, las filas se combinan. ¿Qué sucede cuando no se encuentra una coincidencia? Podemos imaginar cuatro escenarios:\n",
        "\n",
        "1. Solo conservamos las filas de `yelp_df` y `census` si coinciden. Cualquier fila de cualquiera de las tablas que no tenga coincidencia se descarta. Esto se llama una _unión interna_.\n",
        "\n",
        "2. Conservamos todas las filas de `yelp_df` y `census`, incluso si no tienen ninguna coincidencia. En este caso, cuando una fila en `yelp_df` no tiene ninguna coincidencia en `census`, todas las columnas de `census` se fusionan con valores nulos. Cuando una fila en `census` no tiene ninguna coincidencia en `yelp_df`, todas las columnas de `yelp_df` se fusionan con valores nulos. Esto se denomina _unión externa_.\n",
        "\n",
        "3. Privilegiamos los datos `yelp_df`. Si una fila en `yelp_df` no tiene coincidencia en `census`, la conservamos y completamos las columnas `census` faltantes como valores nulos. Si una fila en `census` no tiene coincidencia en `yelp_df`, la descartamos. Esto se denomina _unión izquierda_.\n",
        "\n",
        "4. Privilegiamos los datos `census`. Esto se denomina _unión derecha_.\n",
        "\n",
        "El comportamiento predeterminado para Pandas es el caso n.° 1, la _unión interna_. Esto significa que si hay ciudades en `yelp_df` para las que no tenemos datos `census` coincidentes, se descartan. Por lo tanto, `merged_df` puede ser más pequeño que `yelp_df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNl2YbXVdyG-"
      },
      "outputs": [],
      "source": [
        "print(yelp_df.shape)\n",
        "print(merged_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCJjAybqdyG-"
      },
      "source": [
        "Hay muchas ciudades en `yelp_df` que no están en `census`. Es posible que queramos conservar estas filas, pero no necesitamos ningún dato del censo en el que no haya empresas. En ese caso, deberíamos utilizar una combinación _left join_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_OB8vIEdyG-"
      },
      "outputs": [],
      "source": [
        "merged_df = yelp_df.merge(census, on=['state', 'city'], how='left')\n",
        "print(yelp_df.shape)\n",
        "print(merged_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4H3CBDAdyG_"
      },
      "source": [
        "A veces no necesitamos fusionar las columnas de conjuntos de datos separados, sino que simplemente necesitamos agregar más filas. Por ejemplo, el sistema de metro de la ciudad de Nueva York [publica datos sobre cuántos clientes entran y salen de la estación cada semana](http://web.mta.info/developers/turnstile.html). Cada conjunto de datos semanal tiene las mismas columnas, por lo que si queremos varias semanas de datos, simplemente tenemos que agregar una semana a otra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8tXl77AdyG_"
      },
      "outputs": [],
      "source": [
        "nov18 = pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_171118.txt')\n",
        "nov11 = pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_171111.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoDvgVTCdyG_"
      },
      "outputs": [],
      "source": [
        "nov18.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcfIkiOgdyG_"
      },
      "outputs": [],
      "source": [
        "nov11.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUsD_2WwdyG_"
      },
      "outputs": [],
      "source": [
        "nov = pd.concat([nov18, nov11])\n",
        "nov['DATE'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZxW2iHldyG_"
      },
      "source": [
        "También podemos realizar uniones internas y externas basadas en el índice. Por ejemplo, podemos realizar alguna agregación de datos y luego unir los resultados en el DataFrame original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZkjT5y1dyG_"
      },
      "outputs": [],
      "source": [
        "city_counts = yelp_df.groupby('city')['business_id'].count().rename('city_counts')\n",
        "city_counts.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y54GVrRLdyG_"
      },
      "outputs": [],
      "source": [
        "# Asegurarse de que city_counts también tenga 'city' como índice\n",
        "yelp_df_with_counts = yelp_df.set_index('city').join(city_counts, how='inner').reset_index()\n",
        "yelp_df_with_counts.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2rVjgs-dyG_"
      },
      "source": [
        "Pandas proporciona [extensa documentación](https://pandas.pydata.org/pandas-docs/stable/merging.html) con ejemplos diagramados sobre diferentes métodos y enfoques para unir datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P70XSYMEdyG_"
      },
      "source": [
        "## Trabajar con series temporales\n",
        "Pandas tiene un backend bien diseñado para inferir fechas y horas a partir de cadenas y realizar cálculos significativos con ellas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCbOeqKgdyG_"
      },
      "outputs": [],
      "source": [
        "pop_growth = pd.read_html('https://web.archive.org/web/20170127165708/https://www.census.gov/population/international/data/worldpop/table_population.php', attrs={'class': 'query_table'}, parse_dates=[0])[0]\n",
        "pop_growth.dropna(inplace=True)\n",
        "pop_growth.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7R4uUi2dyG_"
      },
      "source": [
        "Al establecer la columna `'Año'` en el índice, podemos agregar fácilmente datos por fecha utilizando el método `resample`. El método `resample` nos permite disminuir o aumentar la frecuencia de muestreo de nuestros datos. Por ejemplo, tal vez en lugar de datos anuales, queremos ver cantidades promedio para cada década."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGzTShltdyG_"
      },
      "outputs": [],
      "source": [
        "pop_growth.set_index('Year', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5zBuOytdyG_"
      },
      "outputs": [],
      "source": [
        "pop_growth.resample('10AS').mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npLKCzzZKimO"
      },
      "source": [
        "El método `resample()` en pandas se utiliza para agrupar datos a intervalos regulares a lo largo de un eje basado en el tiempo. En este caso, se está utilizando `resample('10AS')`, lo que significa que se está reagrupando la serie de tiempo en intervalos de 10 años. Vamos a desglosarlo paso a paso.\n",
        "\n",
        "### Explicación paso a paso del código:\n",
        "\n",
        "```python\n",
        "pop_growth.resample('10AS').mean()\n",
        "```\n",
        "\n",
        "#### 1. **`pop_growth`**:\n",
        "   - **Descripción**: Asumimos que `pop_growth` es un objeto `pandas.Series` o `pandas.DataFrame` donde el índice es de tipo `DatetimeIndex` o `PeriodIndex`, es decir, una serie de tiempo con fechas o períodos en el índice. Los valores asociados podrían representar, por ejemplo, el crecimiento de la población, aunque eso dependerá del contexto de los datos.\n",
        "\n",
        "#### 2. **`resample('10AS')`**:\n",
        "   - **Propósito**: Agrupa los datos de la serie de tiempo en intervalos de 10 años.\n",
        "   - **Detalles**:\n",
        "     - **`'10AS'`**: Especifica que queremos hacer una reagrupación de los datos en periodos de **10 años**.\n",
        "       - **`10A`**: Significa que se agrupan los datos en bloques de 10 años.\n",
        "       - **`S`**: Indica que los intervalos deben comenzar al **inicio del año**.\n",
        "     - Esto significa que pandas va a tomar el índice de fechas o períodos de `pop_growth` y lo dividirá en intervalos de 10 años, donde cada intervalo comenzará el **1 de enero de un año múltiplo de 10** (como 2000, 2010, etc.).\n",
        "\n",
        "   - **Resultado**: Se crea un objeto `Resampler` que puede ser utilizado para aplicar funciones de agregación sobre los intervalos de tiempo.\n",
        "\n",
        "#### 3. **`.mean()`**:\n",
        "   - **Propósito**: Calcula la **media** de los datos dentro de cada intervalo de 10 años.\n",
        "   - **Detalles**:\n",
        "     - Después de hacer la agrupación en intervalos de 10 años, pandas aplica la función de **media** (`mean()`) a cada grupo. Es decir, para cada intervalo de 10 años, se toma la media de los valores de esa década.\n",
        "   \n",
        "   - **Resultado**: El resultado será una nueva serie de tiempo, donde cada valor es la media del crecimiento de la población (o el dato correspondiente en `pop_growth`) dentro del intervalo de 10 años.\n",
        "\n",
        "#### Ejemplo práctico:\n",
        "\n",
        "Si tienes una serie de tiempo con datos anuales sobre el crecimiento de la población, como:\n",
        "\n",
        "| Fecha       | Crecimiento Población |\n",
        "|-------------|-----------------------|\n",
        "| 2000-01-01  | 1.2%                  |\n",
        "| 2001-01-01  | 1.5%                  |\n",
        "| 2002-01-01  | 1.3%                  |\n",
        "| ...         | ...                   |\n",
        "| 2009-01-01  | 1.1%                  |\n",
        "| 2010-01-01  | 0.9%                  |\n",
        "| ...         | ...                   |\n",
        "\n",
        "Al aplicar `resample('10AS')`, pandas agruparía los datos desde el **1 de enero de 2000 hasta el 31 de diciembre de 2009** en un intervalo, calcularía la media de esos valores, y luego crearía otro grupo desde el **1 de enero de 2010 hasta el 31 de diciembre de 2019**, y así sucesivamente.\n",
        "\n",
        "### Resultado final:\n",
        "Obtendrás un nuevo DataFrame o Serie con valores de media para cada intervalo de 10 años, como:\n",
        "\n",
        "| Fecha       | Media Crecimiento |\n",
        "|-------------|-------------------|\n",
        "| 2000-01-01  | 1.3%              |\n",
        "| 2010-01-01  | 1.0%              |\n",
        "| ...         | ...               |\n",
        "\n",
        "### Resumen:\n",
        "El código agrupa los datos de `pop_growth` en intervalos de 10 años que comienzan al inicio de cada década y luego calcula la media de los valores dentro de esos intervalos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT8qElq8dyG_"
      },
      "source": [
        "Este tipo de remuestreo se denomina _submuestreo_, porque estamos disminuyendo la frecuencia de muestreo de los datos. Podemos elegir cómo agregar los datos de cada década (por ejemplo, `media`). Las opciones de agregación incluyen `media`, `mediana`, `suma`, `último` y `primero`.\n",
        "\n",
        "También podemos _submuestrear_ los datos. En este caso, no tenemos datos para cada trimestre, por lo que tenemos que indicarle a Pandas que complete los datos faltantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI-4JbFrdyG_"
      },
      "outputs": [],
      "source": [
        "pop_growth.resample('1Q').bfill().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQNBWzxbK_YE"
      },
      "source": [
        "El código `pop_growth.resample('1Q').bfill().head()` está realizando un conjunto de operaciones comunes con datos de series de tiempo en pandas. Vamos a desglosarlo paso a paso.\n",
        "\n",
        "### 1. **`pop_growth.resample('1Q')`**:\n",
        "   - **Propósito**: Agrupar los datos de la serie `pop_growth` en intervalos trimestrales.\n",
        "   - **Detalles**:\n",
        "     - **`'1Q'`**: Significa que se desea agrupar los datos en intervalos de **un trimestre**. Un trimestre abarca tres meses, por lo que los datos serán agrupados por periodos de enero-marzo, abril-junio, julio-septiembre, y octubre-diciembre de cada año.\n",
        "     - `resample()` es similar a `groupby()` pero aplicado sobre un índice de tiempo, lo que permite realizar agregaciones o transformaciones en esos intervalos de tiempo.\n",
        "\n",
        "   - **Resultado**: Crea un objeto `Resampler` que contiene los datos organizados por intervalos trimestrales. Aún no se han aplicado operaciones, solo se ha creado la agrupación.\n",
        "\n",
        "### 2. **`.bfill()`**:\n",
        "   - **Propósito**: Rellenar valores faltantes o NaN usando el método de **backward fill** (relleno hacia atrás).\n",
        "   - **Detalles**:\n",
        "     - **`bfill()`** (backfill) significa que cualquier valor que falte en los nuevos intervalos creados (en este caso, los trimestres) será rellenado con el **siguiente valor válido** en la serie de tiempo.\n",
        "     - Si en un trimestre no hay datos, pandas buscará el valor del trimestre siguiente y rellenará con ese valor.\n",
        "     - Este método es útil cuando, al hacer `resample()`, hay intervalos sin datos y quieres evitar valores `NaN`, utilizando el siguiente valor disponible.\n",
        "\n",
        "   - **Ejemplo**:\n",
        "     - Si tienes datos mensuales y resampleas a intervalos trimestrales, es posible que algunos trimestres no tengan datos. Con `bfill()`, esos trimestres se llenarán con el valor del trimestre siguiente.\n",
        "\n",
        "   - **Resultado**: Después de la resampleación, cualquier trimestre vacío o sin datos se rellenará con el valor del siguiente trimestre disponible.\n",
        "\n",
        "### 3. **`.head()`**:\n",
        "   - **Propósito**: Muestra las primeras 5 filas del DataFrame o Serie resultante.\n",
        "   - **Detalles**:\n",
        "     - Esto es una forma común de verificar rápidamente el resultado de una operación en pandas sin visualizar el conjunto de datos completo.\n",
        "\n",
        "### Ejemplo práctico:\n",
        "\n",
        "Supongamos que tienes la siguiente serie de tiempo con datos anuales de crecimiento poblacional, pero quieres agruparla trimestralmente y rellenar los valores faltantes hacia atrás:\n",
        "\n",
        "| Fecha       | Crecimiento Población |\n",
        "|-------------|-----------------------|\n",
        "| 2000-01-01  | 1.2%                  |\n",
        "| 2001-01-01  | 1.4%                  |\n",
        "| 2002-01-01  | 1.3%                  |\n",
        "| 2004-01-01  | 1.0%                  |\n",
        "\n",
        "Si aplicas `resample('1Q').bfill()`, pandas agrupará los datos trimestralmente. Como no hay datos para algunos trimestres (por ejemplo, entre abril y diciembre de 2000), rellenará esos trimestres con el siguiente valor válido disponible.\n",
        "\n",
        "El resultado sería algo como:\n",
        "\n",
        "| Fecha       | Crecimiento Población |\n",
        "|-------------|-----------------------|\n",
        "| 2000-03-31  | 1.2%                  |\n",
        "| 2000-06-30  | 1.4%                  |\n",
        "| 2000-09-30  | 1.4%                  |\n",
        "| 2000-12-31  | 1.4%                  |\n",
        "| 2001-03-31  | 1.4%                  |\n",
        "\n",
        "### Resumen:\n",
        "- **`resample('1Q')`** agrupa los datos de la serie `pop_growth` en intervalos trimestrales.\n",
        "- **`bfill()`** rellena los valores faltantes en los trimestres vacíos con el siguiente valor disponible en la serie de tiempo.\n",
        "- **`head()`** simplemente muestra las primeras 5 filas del resultado.\n",
        "\n",
        "Este método es útil cuando tienes datos con una frecuencia más baja (por ejemplo, anual o mensual) y deseas transformarlos en datos trimestrales sin tener valores `NaN` en los nuevos intervalos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcBdnR4kdyG_"
      },
      "outputs": [],
      "source": [
        "pop_growth.resample('1Q').ffill().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BszrZ6sLrdM"
      },
      "source": [
        "El código `pop_growth.resample('1Q').ffill().head()` realiza operaciones sobre una serie de tiempo en pandas, utilizando el método `resample()` para agrupar los datos en intervalos trimestrales y luego rellenar los valores faltantes hacia adelante con `ffill()`. A continuación te explico paso a paso cómo funciona este código.\n",
        "\n",
        "### 1. **`pop_growth.resample('1Q')`**:\n",
        "   - **Propósito**: Agrupar los datos de la serie `pop_growth` en intervalos de **un trimestre**.\n",
        "   - **Detalles**:\n",
        "     - **`'1Q'`**: Especifica que queremos reorganizar los datos en bloques trimestrales (cada 3 meses). Los trimestres se dividen de la siguiente forma: enero-marzo, abril-junio, julio-septiembre, y octubre-diciembre.\n",
        "     - `resample()` actúa de manera similar a `groupby()`, pero en lugar de agrupar por categorías, se agrupa por periodos de tiempo definidos (en este caso, por trimestres).\n",
        "   \n",
        "   - **Resultado**: Se crea un objeto `Resampler` que organiza los datos en intervalos trimestrales. No se han realizado operaciones aún; simplemente se agrupan los datos en periodos de 3 meses.\n",
        "\n",
        "### 2. **`.ffill()`** (Forward Fill):\n",
        "   - **Propósito**: Rellenar los valores faltantes hacia adelante.\n",
        "   - **Detalles**:\n",
        "     - **`ffill()`** significa **\"forward fill\"** (relleno hacia adelante). Esto indica que cuando faltan datos en un periodo de tiempo, se rellena ese vacío con el **último valor conocido**.\n",
        "     - Este método es útil para garantizar que no haya valores `NaN` en el resultado al rellenar los huecos con el valor más reciente que se tiene antes del hueco.\n",
        "\n",
        "   - **Ejemplo**:\n",
        "     - Si tienes un valor válido en enero pero no tienes ningún dato hasta mayo, todos los trimestres intermedios (febrero-marzo, abril-junio) se rellenarán con el valor de enero.\n",
        "\n",
        "   - **Resultado**: Después de hacer `resample()`, los trimestres que no tienen datos recibirán el valor del trimestre inmediatamente anterior.\n",
        "\n",
        "### 3. **`.head()`**:\n",
        "   - **Propósito**: Muestra las primeras 5 filas del DataFrame o Serie resultante.\n",
        "   - **Detalles**:\n",
        "     - Este método es útil para visualizar rápidamente las primeras filas del DataFrame o Serie después de aplicar las operaciones, facilitando la revisión de los resultados.\n",
        "\n",
        "### Ejemplo práctico:\n",
        "\n",
        "Supongamos que tienes una serie de tiempo de crecimiento poblacional en intervalos anuales, pero quieres agrupar estos datos en intervalos trimestrales y rellenar cualquier vacío con el último valor disponible.\n",
        "\n",
        "| Fecha       | Crecimiento Población |\n",
        "|-------------|-----------------------|\n",
        "| 2000-01-01  | 1.2%                  |\n",
        "| 2001-01-01  | 1.4%                  |\n",
        "| 2002-01-01  | 1.3%                  |\n",
        "| 2004-01-01  | 1.0%                  |\n",
        "\n",
        "Al aplicar `resample('1Q').ffill()`, pandas reagrupa los datos en trimestres. Dado que los datos originales solo están presentes al inicio de cada año, los trimestres intermedios se rellenarán con el valor del trimestre anterior:\n",
        "\n",
        "| Fecha       | Crecimiento Población |\n",
        "|-------------|-----------------------|\n",
        "| 2000-03-31  | 1.2%                  |\n",
        "| 2000-06-30  | 1.2%                  |\n",
        "| 2000-09-30  | 1.2%                  |\n",
        "| 2000-12-31  | 1.2%                  |\n",
        "| 2001-03-31  | 1.4%                  |\n",
        "\n",
        "En este ejemplo, los trimestres del 2000 sin datos se rellenan con el valor de enero de 2000 (1.2%), y los trimestres de 2001 con el valor de enero de 2001 (1.4%).\n",
        "\n",
        "### Resumen:\n",
        "- **`resample('1Q')`**: Agrupa los datos de la serie de tiempo en intervalos trimestrales.\n",
        "- **`ffill()`**: Rellena los trimestres vacíos o sin datos con el último valor conocido hacia adelante.\n",
        "- **`head()`**: Muestra las primeras 5 filas del resultado.\n",
        "\n",
        "Este proceso es útil cuando trabajas con datos de series de tiempo y necesitas asegurar que cada periodo tenga un valor, incluso si algunos trimestres no tienen observaciones originales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rPWSjrMdyG_"
      },
      "source": [
        "Las capacidades de series de tiempo de Pandas se basan en la clase \"Timestamp\" de Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZEmQkWMdyG_"
      },
      "outputs": [],
      "source": [
        "print(pd.Timestamp('January 8, 2017'))\n",
        "print(pd.Timestamp('01/08/17 20:13'))\n",
        "print(pd.Timestamp(1.4839*10**18))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3yD4t_vdyHA"
      },
      "outputs": [],
      "source": [
        "print( pd.Timestamp('Feb. 11 2016 2:30 am') - pd.Timestamp('2015-08-03 5:14 pm') )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vMBlEI5dyHA"
      },
      "outputs": [],
      "source": [
        "from pandas.tseries.offsets import BDay, Day, BMonthEnd\n",
        "\n",
        "print(pd.Timestamp('January 9, 2017') - Day(4))\n",
        "print(pd.Timestamp('January 9, 2017') - BDay(4))\n",
        "print(pd.Timestamp('January 9, 2017') + BMonthEnd(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRwslJPZL-vM"
      },
      "source": [
        "El código utiliza objetos de la librería `pandas.tseries.offsets` para realizar operaciones con fechas. Las clases `BDay`, `Day`, y `BMonthEnd` son útiles para realizar desplazamientos sobre fechas y tiempos, considerando diferentes tipos de días (días naturales, días hábiles, etc.). Vamos a desglosar cada parte paso a paso.\n",
        "\n",
        "### 1. **`from pandas.tseries.offsets import BDay, Day, BMonthEnd`**:\n",
        "   - **Propósito**: Importar diferentes tipos de desplazamientos de fechas desde `pandas.tseries.offsets`.\n",
        "     - **`BDay`**: Representa un desplazamiento en términos de **días hábiles** (excluyendo fines de semana y feriados).\n",
        "     - **`Day`**: Representa un desplazamiento en **días naturales** (incluyendo todos los días, fines de semana incluidos).\n",
        "     - **`BMonthEnd`**: Representa un desplazamiento hasta el **último día hábil** de un mes.\n",
        "\n",
        "### 2. **`pd.Timestamp('January 9, 2017') - Day(4)`**:\n",
        "   - **`pd.Timestamp('January 9, 2017')`**: Crea un objeto `Timestamp`, que es una representación de una fecha y hora específica en pandas. En este caso, se trata de **9 de enero de 2017**.\n",
        "   - **`Day(4)`**: Representa un desplazamiento de **4 días naturales**.\n",
        "   - **`pd.Timestamp('January 9, 2017') - Day(4)`**: Resta 4 días naturales a la fecha del 9 de enero de 2017. Los días naturales incluyen fines de semana.\n",
        "   \n",
        "   **Resultado**: `2017-01-05`, ya que restar 4 días naturales (enero 5, 2017) da como resultado el 5 de enero de 2017.\n",
        "\n",
        "### 3. **`pd.Timestamp('January 9, 2017') - BDay(4)`**:\n",
        "   - **`pd.Timestamp('January 9, 2017')`**: Mismo `Timestamp` que antes, representa **9 de enero de 2017**.\n",
        "   - **`BDay(4)`**: Representa un desplazamiento de **4 días hábiles** (no se consideran los fines de semana).\n",
        "   - **`pd.Timestamp('January 9, 2017') - BDay(4)`**: Resta 4 días hábiles a la fecha del 9 de enero de 2017. Los días hábiles son los días de lunes a viernes.\n",
        "\n",
        "   **Resultado**: `2017-01-03`. Si restas 4 días hábiles al 9 de enero de 2017:\n",
        "   - 6 de enero (viernes),\n",
        "   - 5 de enero (jueves),\n",
        "   - 4 de enero (miércoles),\n",
        "   - 3 de enero (martes).\n",
        "\n",
        "### 4. **`pd.Timestamp('January 9, 2017') + BMonthEnd(4)`**:\n",
        "   - **`pd.Timestamp('January 9, 2017')`**: Mismo `Timestamp`, representa **9 de enero de 2017**.\n",
        "   - **`BMonthEnd(4)`**: Representa un desplazamiento de **4 fines de mes hábiles**. Es decir, se avanza hasta el **último día hábil** de cada mes y se repite este proceso 4 veces.\n",
        "   - **`pd.Timestamp('January 9, 2017') + BMonthEnd(4)`**: Avanza hasta el último día hábil de cada uno de los siguientes 4 meses.\n",
        "\n",
        "   **Resultado**: `2017-04-28`. Al sumar 4 fines de mes hábiles al 9 de enero de 2017:\n",
        "   - El último día hábil de enero 2017 es el **31 de enero de 2017**.\n",
        "   - El último día hábil de febrero 2017 es el **28 de febrero de 2017**.\n",
        "   - El último día hábil de marzo 2017 es el **31 de marzo de 2017**.\n",
        "   - El último día hábil de abril 2017 es el **28 de abril de 2017**.\n",
        "\n",
        "### Resumen:\n",
        "1. **`Day(4)`**: Resta 4 días naturales (incluyendo fines de semana) → 5 de enero de 2017.\n",
        "2. **`BDay(4)`**: Resta 4 días hábiles (solo cuenta de lunes a viernes) → 3 de enero de 2017.\n",
        "3. **`BMonthEnd(4)`**: Avanza hasta el último día hábil de 4 meses consecutivos → 28 de abril de 2017.\n",
        "\n",
        "Este tipo de operaciones es útil para trabajar con series temporales en pandas, donde se necesitan realizar cálculos con días hábiles o naturales, o desplazamientos hasta fines de mes específicos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SCi26uCdyHA"
      },
      "source": [
        "Si ingresamos datos de series de tiempo en un DataFrame, a menudo será útil crear un rango de fechas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_szhKL9dyHA"
      },
      "outputs": [],
      "source": [
        "pd.date_range(start='1/8/2017', end='3/2/2017', freq='B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-SrYKl7M5Jc"
      },
      "source": [
        "* freq='B': Solo se incluyen días hábiles (lunes a viernes), excluyendo los fines de semana.\n",
        "\n",
        "El rango resultante es útil en casos en los que necesitas trabajar con series de tiempo y solo quieres considerar días laborales (por ejemplo, para análisis financiero o datos de negocios)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvs2LabVdyHA"
      },
      "source": [
        "La clase `Timestamp` es compatible con el módulo `datetime` de Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imJkjXYcdyHA"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "pd.Timestamp('May 1, 2017') - datetime.datetime(2017, 1, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3h_iJcTdyHA"
      },
      "source": [
        "## Visualizar datos con Pandas\n",
        "\n",
        "Visualizar un conjunto de datos es un primer paso importante para extraer información. Podemos pasar fácilmente datos de Pandas a Matplotlib para realizar visualizaciones, pero Pandas también se conecta directamente a Matplotlib a través de métodos como `plot` y `hist`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH7iMHMqdyHA"
      },
      "outputs": [],
      "source": [
        "yelp_df['review_count'].apply(np.log).hist(bins=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ogwmr1LmdyHB"
      },
      "outputs": [],
      "source": [
        "pop_growth['Annual Growth Rate (%)'].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQlQDeDjdyHB"
      },
      "source": [
        "Las [funciones de representación gráfica toman muchos parámetros](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html) para personalizar la apariencia de la salida. Dado que son esencialmente un contenedor de las funciones de Matplotlib, también aceptan muchos de los parámetros de Matplotlib, no todos los cuales se encuentran en la documentación de Pandas. Pandas proporciona [una guía](https://pandas.pydata.org/pandas-docs/stable/visualization.html) para crear varios gráficos a partir de DataFrames."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "nbclean": true
  },
  "nbformat": 4,
  "nbformat_minor": 0
}